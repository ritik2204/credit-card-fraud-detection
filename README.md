About Project
Project Objective:
The chosen project aims to develop Deep learning models for predicting fraudulent credit card transactions using customer-level data collected and analyzed in collaboration with Worldline and the Machine Learning Group. 

Business Problem Overview:
In the banking sector, preserving high-profit customer relationships stands as a paramount objective. However, banking fraud presents a formidable challenge to this goal across various financial institutions. The substantial financial losses incurred, along with erosion of trust and credibility, pose significant concerns for both banks and customers.

According to estimates from the Nilson Report, global banking fraud was projected to reach $30 billion by 2020. With the proliferation of digital payment channels, fraudulent transactions continue to increase in both frequency and sophistication.

Credit card fraud detection leveraging machine learning methodologies is not merely a trend but a vital necessity for banks to establish proactive monitoring and fraud prevention mechanisms. Machine learning empowers these institutions to streamline operations by reducing time-intensive manual reviews, mitigating costly chargebacks and fees, and minimizing denials of legitimate transactions.

Understanding and Defining Fraud:
Credit card fraud encompasses any illicit act aimed at obtaining financial gain without proper authorization from the account holder. Among various fraudulent methods, skimming emerges as the most prevalent, involving the duplication of information stored on the magnetic strip of the card. Additionally, fraud may manifest through manipulation or alteration of genuine cards, creation of counterfeit cards, exploitation of stolen or lost credit cards, and fraudulent telemarketing schemes.

Project Pipeline:
The project's procedural flow comprises the following four distinct phases:

1. Data Understanding: In this phase, the data is loaded and analyzed to comprehend the available features, facilitating the selection of relevant attributes for the final model.

2. Exploratory Data Analysis (EDA): EDA involves univariate and bivariate analyses of the data, coupled with feature transformations as necessary. While Z-scaling might not be required due to Gaussian variables, identifying and mitigating any skewness in the data is imperative to prevent potential complications during model development.

3. Train/Test Split: The dataset is partitioned into training and testing sets to evaluate model performance on unseen data. Utilizing k-fold cross-validation ensures appropriate representation of the minority class in the test folds.

4. Model Building/Hyperparameter Tuning: This phase entails experimentation with various machine learning models and fine-tuning their hyperparameters to achieve optimal performance on the dataset. Employing different sampling techniques allows for exploration of improved model efficacy.

5. Model Evaluation: Models are assessed using suitable evaluation metrics, with emphasis placed on accurately identifying fraudulent transactions. Selecting an evaluation metric aligned with this business objective is paramount to gauging model effectiveness.
#####################################################################################################################################################################################################################
For Dataset you can just simply follow this Link and Download the Data set.
Link : https://drive.google.com/file/d/10ma2jFu0vx9Ph73ufHk1EcZ8EkBKQvUC/view?usp=sharing
